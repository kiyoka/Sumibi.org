

             変換アルゴリズム

                Design memo
          

1. 基本アイデア
  - マルコフ連鎖モデルを使い、最適な単語の決定を行う。
  - 隣接する２つの単語の出現頻度をデータベースに保持し
    ある単語の直後に出現する単語の出現確率をもとに、
    マルコフ連鎖モデルで計算する。


2. データベースの構造
  - SQLデータベースを使う
  - sumi データベースの構造
    「word:語彙テーブル] ... SKK の辞書に似た感じとなる
      - id:単語
      - kind:種別
        + s:SKK登録済み単語
        + c:未知語:学習中にコーパスから獲得した語彙
        + n:数値
        + U:URL
      - yomiank:ANK
      - yomi:ひらがな
      - okuri:送りがなの頭文字
      - tango:漢字を含む単語文字列 ( 送りがなを含まない )
      - freq_base:出現頻度(コーパスでの出現回数)
      - freq_user:出現頻度(ユーザ入力での出現回数)
    [bigram:出現頻度テーブル]
      - id_m1   :単語id(id_baseの前に隣接した単語)
      - id_base :単語id(基準)
      - freq_base:出現頻度(コーパスでの出現回数)
      - freq_user:出現頻度(ユーザ入力での出現回数)
  - 文字エンコードは、UTF-8とする。
    ( 将来的にEUC 等では表現できない文字も入るようにする。 )

3. ANK から辞書の単語検索
  - 送りがなを含む辞書検索の基本
    例えば、ユーザーが「行う」という単語を変換しようとした場合、
    okonau と入力されるので yomiank="oko" okuri="n" までの時点でマッチするので、
    「行う」が検索対象に含まれる。
    同時に、yomiank="okona" okuri="u" にもマッチするので、「行なう」も検索対象となる。
    なお、どちらの単語が選択されるかどうかは、文脈や頻度によって決まる。

  - 送りがなの処理については活用などの処理はしない。
    okonaunari という文節が記述された場合でも okuri="n" にマッチしているので
    「行なうなり」 と変換する。

4. 課題
  - 自分の好きな送りがなを指定したいときはどうするか。
    いろんな人の書いたコーパスから学習するため、送りがなの書き方は、
    文脈によって揺れが発生する。
    どちらを優先するかを設定できるようにしたい。

    案1) 単語毎に設定できるようにする
    案2) 傾向だけを設定できるようにする
         例えば、送りがなはなるべく短くする／長くする等を選択する等。

  - コーパスに登場しなかった語の頻度をどうやってごまかすか。
    マルコフ連鎖モデルを使うと、頻度ゼロの単語が現れると、文章全体がその語順になる
    確率がゼロになってしまうため、問題となる。
    もし、コーパスの量が少なかった場合に、ほとんどの文章があり得ない文章となる。

    例えば、以下の文章で 「中野」 と 「です」 の連続がコーパスに出現したことが無かった
    場合、以下の文章の確からしさは、ゼロとなる。

    watashi no namae ha nakano desu.
        ↓ 
    私の名前は中野です。

    案1) 例えば、1% 固定とする(超いい加減な案)
    案2) 例えば、最低１回は出現したことがあるものとする。
         確率 =  1 / [中野の次に出現した単語の全ての頻度+1] という式で求める。

         このとき、もし、中野の次に一度も単語が出現したことが無かったら、
         1 / 1 となる。すなわちこれは知らない並びにであったときは、
         全面的に人間を信用すると言うことを意味する。


5. 問題点と解決策
  Q 辞書に、平仮名のみの長い単語が入ってしまう。どうするか。
    例えば次のような単語が入ってしまう。
     (13217 c denakerebanaranaitoiu でなければならないという  0)

  A 案１
    ６文字以上の平仮名の並びは単語として登録しない等で逃げる。


[EOF]

